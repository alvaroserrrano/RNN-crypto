{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptocurrencies Price Prediction using a RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "An investment in bitcoin is the equivalent of betting on the increased adoption of this asset. Contrary to the US dollar, which used to be backed by gold and currently is backed by trust on the US government) bitcoin itself has no intrinsic value. This means that bitcoin’s market price is based on the law of supply and demand. Furthermore, bitcoin has a cap on the amount of coins produced, namely 21 million. This makes bitcoin a deflationary asset, which translates into a greater economic value as its supply decreases.\n",
    "This project uses machine learning to test if bitcoin’s market price can be significantly predicted by other Bitcoin’s blockchain features such as market price, hash rate, difficulty adjustment, transactions volume… A RNN (Recurrent Neural Network) will be used to predict a time-series dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "- Use a RNN to predict against a time-series dataset of 4 cryptocurrencies: BTC, LTC, ETH, BCH\n",
    "- The goal is that the neural network doesn't just memorize our data and that it instead \"generalizes\" and learns the actual problem and patterns associated with it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "- The data we'll be using is Open, High, Low, Close, Volume data for Bitcoin, Ethereum, Litecoin and Bitcoin Cash.\n",
    "- Since there are different ways to measure the price (opening price, closing price, high price, low price...) we specify that the model uses the `Close` and `Volume` columns from the input dataset\n",
    "- We're going to be tracking the `Close` and `Volume` every minute for Bitcoin, Litecoin, Ethereum, and Bitcoin Cash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis to data set\n",
    "1. Manage input data:\n",
    "\t1.1 Combine price and volume for each coin into a single feature \n",
    "\t1.2 Choose a target: price we are trying to predict and how far out in the future we are considering\n",
    "2. **Feed Forward Neural Network**: Take that feature set and combine it into sequences of 60 feature sets that we will use as input to the model\n",
    "3. Since our output is trying to predict whether price will fall or rise for each cryptocurrencies:\n",
    "\t3.1 Take the price of all assets\n",
    "\t3.2 Take the future price of the asset\n",
    "\t3.3 Determine whether the price will be higher or lower at the current price\n",
    "4. **Balance** the  buys and sells:  make sure that there are the same number of examples for each cryptocurrency (same number of recorded transactions for each coin).\n",
    "\t- a) Feed weights to the model to measure error accordingly\n",
    "\t- b) Trim down datasets to make them all have approximately the same number of transactions recorded\n",
    "\t- Not balancing could lead to a our model to predict only one coin, whichever is the most common, and memorize it\n",
    "5. Scale and normalize the data\n",
    "6. Before creating a target we need to know: \n",
    "\t6.1 Which price we are trying to predict\n",
    "\t6.2 Time frame: how far out we are trying to predict\n",
    "\t- Choose a time frame step: how many observations should be considered when the RNN makes a prediction about the current observation. \n",
    "\t- The longer the sequence the more accurate the prediction will be\n",
    "\t6.3 Make a decision about the classification function we will be using (how are we going to predict the price):\n",
    "\ta) Make it a regression question: using a linear activation with output lyer\n",
    "\tb) Use binary classification\n",
    "7. In this case, we make the decision of following the binary classification strategy:\n",
    "8. Use the classification function to make a target\n",
    "9. Validate the data, sequences, and normalize the data\n",
    "\t9.1 Split training and test datasets: Since the data is inherently sequential, taking sequeneces that do not come in the future is likely a mistake.\n",
    "\t9.2 Validate the data:\n",
    "\t- Sequences that are, for example, 1 minute apart, are likely to be the same, thus indicating an identical Buy or Sell signal\n",
    "\t- This might cause the model to be overfitted on the test split\n",
    "\t- In order to remediate this, the validation data is sliced while it is still in order\n",
    "\t9.3 Create random sequences and shuffle them before balancing\n",
    "10. Apply feature scaling to the dataset:\n",
    "\t- Apply normalization by subtracting the minimum value of the dataset and then dividing by the range of the dataset. ![Feature scaling normalization equation](https://nickmccullum.com/images/python-deep-learning/recurrent-neural-networks/normalization.jpg)\n",
    "\t- Scale the data and normalize all except for the target column itself. \n",
    "\t- We use percentage change in price to normalize the prices of all cryptocurrencies. The reason for that is that each cryptocurrency has very different values and, therefore, we care about the other coins' movements.\n",
    "11. Model building and training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/alvaroserranorivas/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: tensorflow in /Users/alvaroserranorivas/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: keras in /Users/alvaroserranorivas/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: pandas in /Users/alvaroserranorivas/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in /Users/alvaroserranorivas/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages (1.21.4)\n",
      "Requirement already satisfied: matplotlib in /Users/alvaroserranorivas/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages (3.4.3)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement CuDNN (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for CuDNN\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/alvaroserranorivas/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn tensorflow keras pandas numpy matplotlib CuDNN;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T13:12:01.693529Z",
     "start_time": "2021-09-13T13:12:01.693512Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import random\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Keras libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECEDING_PRICES = 60  # preceeding 60 days prices\n",
    "FUTURE_PRICES_PREDICT = 3  # how far into the future to predict\n",
    "EPOCHS = 10  # how many times to train the model\n",
    "BATCH_SIZE = 64  # how many samples per batch\n",
    "NAME = f\"{PRECEDING_PRICES}-SEQ-{FUTURE_PRICES_PREDICT}-PRED-{int(time.time())}\"  \n",
    "TO_PREDICT = \"BTC-USD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The process of building a RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T13:43:20.151383Z",
     "start_time": "2021-09-12T13:43:20.148675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ETH-USD_close  ETH-USD_volume  BTC-USD_close  BTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720      486.01001       26.019083    6487.379883        7.706374   \n",
      "1528968780      486.00000        8.449400    6479.410156        3.088252   \n",
      "1528968840      485.75000       26.994646    6479.410156        1.404100   \n",
      "1528968900      486.00000       77.355759    6479.979980        0.753000   \n",
      "1528968960      486.00000        7.503300    6480.000000        1.490900   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  LTC-USD_close  LTC-USD_volume  \n",
      "time                                                                      \n",
      "1528968720     870.859985       26.856577      96.660004      314.387024  \n",
      "1528968780     870.099976        1.124300      96.570000       77.129799  \n",
      "1528968840     870.789978        1.749862      96.500000        7.216067  \n",
      "1528968900     870.000000        1.680500      96.389999      524.539978  \n",
      "1528968960     869.989990        1.669014      96.519997       16.991997  \n"
     ]
    }
   ],
   "source": [
    "main_df = pd.DataFrame() \n",
    "\n",
    "data_directory: Path = Path(\"./crypto-data\")\n",
    "\n",
    "for file in data_directory.glob(\"*.csv\"):\n",
    "    file_name = file.name.split(\".\")[0]\n",
    "    df = pd.read_csv(f\"{data_directory.name}/{file.name}\", names = [\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"],  encoding=\"ISO-8859-1\")\n",
    "    # rename to distinguish the cryptocurrency we are working with\n",
    "    df.rename(columns={\"close\": f\"{file_name}_close\", \"volume\": f\"{file_name}_volume\"}, inplace=True)\n",
    "    # set time as index (row labels) so we can join the dataframes\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    # drop columns we are not interested in\n",
    "    df = df[[f\"{file_name}_close\", f\"{file_name}_volume\"]]\n",
    "    # drop rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    main_df = df if len(main_df) == 0 else main_df.join(df)\n",
    "\n",
    "main_df.fillna(method=\"ffill\", inplace=True) \n",
    "main_df.dropna(inplace=True)\n",
    "print(main_df.head())\n",
    "# # use previous valid value if there are gaps in the data\n",
    "# main_df.fillna(method=\"ffill\", inplace=True) \n",
    "# # main_df.fillna(method=\"bfill\", inplace=True)\n",
    "# main_df.dropna(inplace=True)\n",
    "# print(main_df.shape)\n",
    "# print(main_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define logic for making a decision (Buy/Sell)\n",
    "- If the \"future\" column is higher, we buy.\n",
    "- Else,we sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_order_decision(current_price, future_price):\n",
    "\tif float(current_price) < float(future_price): \n",
    "\t\treturn 1 # buy order\n",
    "\telse:\n",
    "\t\treturn 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Speculate future price based on closing prices from the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column with the target future value\n",
    "main_df[\"future_price_to_predict\"] = main_df[f\"{TO_PREDICT}_close\"].shift(-FUTURE_PRICES_PREDICT) # negative to shift columnn up\n",
    "# main_df[\"future_price_to_predict\"] = main_df[\"future_price_to_predict\"].astype(float)\n",
    "main_df[\"order_decision\"] = list(map(make_order_decision, main_df[f\"{TO_PREDICT}_close\"], main_df[\"future_price_to_predict\"]))\n",
    "main_df.dropna(inplace=True)\n",
    "# print(main_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply feature scaling to the dataset\n",
    "There are 2 alternatives:\n",
    "- Standardization\n",
    "- Normalization: ![Feature scaling normalization equation](https://nickmccullum.com/images/python-deep-learning/recurrent-neural-networks/normalization.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalization of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data except for the order_decision column\n",
    "def normalize_and_scale_df(df):\n",
    "\t# no longer need future_price_to_predict column\n",
    "\tdf = df.drop(\"future_price_to_predict\", axis=1)\n",
    "\n",
    "\tfor column in df.columns:\n",
    "\t\tif column != \"order_decision\":\n",
    "\t\t\tdf[column] = df[column].pct_change()\n",
    "\t\t\tdf.dropna(inplace=True)\n",
    "\t\t\tdf[column] = preprocessing.scale(df[column].values)\n",
    "\t\t\t# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\t\t\t# data_scaled = min_max_scaler.fit_transform(df[column].values.reshape(-1, 1))\n",
    "\t\t\t# df[column] = data_scaled\n",
    "\n",
    "\tdf.dropna(inplace=True)\n",
    "\n",
    "\tpredictions_sequence = []\n",
    "\tprevious_days_sequence = deque(maxlen=PRECEDING_PRICES)\t\n",
    "\n",
    "\tfor value in df.values:\n",
    "\t\tprevious_days_sequence.append([i for i in value[:-1]])\n",
    "\t\tif len(previous_days_sequence) == PRECEDING_PRICES:\n",
    "\t\t\tpredictions_sequence.append([np.array(previous_days_sequence), value[-1]])\n",
    "\t# shuffle sequential data for good measure\n",
    "\trandom.shuffle(predictions_sequence)\n",
    "\n",
    "\tbuy_orders = []\n",
    "\tnot_buy_orders = []\n",
    "\n",
    "\tfor sequence, order_decision in predictions_sequence:\n",
    "\t\tif order_decision == 1:\n",
    "\t\t\tbuy_orders.append([sequence, order_decision])\n",
    "\t\telse:\n",
    "\t\t\tnot_buy_orders.append([sequence, order_decision])\n",
    "\t\n",
    "\trandom.shuffle(buy_orders)\n",
    "\trandom.shuffle(not_buy_orders)\n",
    "\n",
    "\t# ensure both buy and not buy orders are the same length\n",
    "\tshorter_sequence = min(len(buy_orders), len(not_buy_orders))\n",
    "\tbuy_orders = buy_orders[:shorter_sequence]\n",
    "\tnot_buy_orders = not_buy_orders[:shorter_sequence]\n",
    "\n",
    "\t# combine buy and not buy orders into predictions_sequence\n",
    "\tpredictions_sequence = buy_orders + not_buy_orders\n",
    "\trandom.shuffle(predictions_sequence)\n",
    "\n",
    "\tx_data = []\n",
    "\ty_data = []\n",
    "\n",
    "\tfor sequence, order_decision in predictions_sequence:\n",
    "\t\tx_data.append(sequence) # sequence is the input\n",
    "\t\ty_data.append(order_decision) # buy or not to buy\n",
    "\t \n",
    "\treturn np.array(x_data), y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test data: (5141, 10)\n",
      "Shape of training data: (97687, 10)\n",
      "            ETH-USD_close  ETH-USD_volume  BTC-USD_close  BTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1534904940     291.140015        6.290395    6705.200195        8.163854   \n",
      "1534905000     291.570007      489.621918    6700.000000        9.827062   \n",
      "1534905060     292.299988      173.859314    6700.000000       13.631424   \n",
      "1534905120     292.399994       77.035606    6702.359863       12.383007   \n",
      "1534905180     292.600006       89.692940    6711.560059       15.645502   \n",
      "...                   ...             ...            ...             ...   \n",
      "1535214840     279.290009        4.150405    6710.089844        1.293573   \n",
      "1535214900     279.299988        5.566861    6712.990234        2.330975   \n",
      "1535214960     279.359985       11.280577    6713.140137        0.769891   \n",
      "1535215020     279.359985        8.790519    6714.520020        1.002652   \n",
      "1535215080     279.369995        1.311763    6714.520020        1.021925   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1534904940     559.989990        5.615524      58.220001      135.698441   \n",
      "1534905000     558.239990       35.015507      57.930000      864.464905   \n",
      "1534905060     560.640015       84.553719      58.250000      563.237671   \n",
      "1534905120     560.229980      101.587196      58.439999      422.931000   \n",
      "1534905180     560.979980       53.466728      58.450001       23.478930   \n",
      "...                   ...             ...            ...             ...   \n",
      "1535214840     531.479980        0.044015      58.009998       93.464951   \n",
      "1535214900     531.469971        1.761348      58.020000        0.823356   \n",
      "1535214960     531.479980        1.208560      58.020000        6.434783   \n",
      "1535215020     531.479980        0.016868      58.009998        7.301921   \n",
      "1535215080     531.469971        0.013854      58.020000       23.802017   \n",
      "\n",
      "            future_price_to_predict  order_decision  \n",
      "time                                                 \n",
      "1534904940              6702.359863               0  \n",
      "1534905000              6711.560059               1  \n",
      "1534905060              6710.000000               1  \n",
      "1534905120              6701.379883               0  \n",
      "1534905180              6704.790039               0  \n",
      "...                             ...             ...  \n",
      "1535214840              6714.520020               1  \n",
      "1535214900              6714.520020               1  \n",
      "1535214960              6715.000000               1  \n",
      "1535215020              6715.000000               1  \n",
      "1535215080              6715.000000               1  \n",
      "\n",
      "[5141 rows x 10 columns]\n",
      "train data: 82722 test data: 4726\n",
      "Train Dont buys: 41361, buys: 41361\n",
      "Test Dont buys: 2363, buys: 2363\n"
     ]
    }
   ],
   "source": [
    "# data will not be shuffled due to the nature of the data, which is sequential\n",
    "# taking sequences of data that do not come in the future is likely a bad idea\n",
    "# make_order_decision will usually be the same for data points 1 minute apart\n",
    "sorted_dates = sorted(main_df.index.values)\n",
    "last_5_percent = sorted(main_df.index.values)[-int(len(sorted_dates) * 0.05)]\n",
    "\n",
    "test_df = main_df[(main_df.index >= last_5_percent)]\n",
    "print(f\"Shape of test data: {test_df.shape}\")\n",
    "main_df = main_df[(main_df.index < last_5_percent)]\n",
    "print(f\"Shape of training data: {main_df.shape}\")\n",
    "\n",
    "# train test split\n",
    "# normalize and scale training data\n",
    "# x_train is a numpy array of sequences\n",
    "# y_train is a list of buy or not to buy (1 or 0)\n",
    "x_train, y_train = normalize_and_scale_df(main_df)\n",
    "# normalize and scale test data\n",
    "x_test, y_test = normalize_and_scale_df(test_df)\n",
    "print(test_df)\n",
    "\n",
    "print(f\"train data: {len(x_train)} test data: {len(x_test)}\")\n",
    "print(f\"Train Dont buys: {y_train.count(0)}, buys: {y_train.count(1)}\")\n",
    "print(f\"Test Dont buys: {y_test.count(0)}, buys: {y_test.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and traing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(x_train.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Compilation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alvaroserranorivas/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  \n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(model_checkpoint, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Traning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'numpy.float64'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tc/8qx_qhb91gj75ryhvz_t9td80000gn/T/ipykernel_24694/4019748008.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.2/envs/bitcoin_linear_regression/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'numpy.float64'>\"})"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15a757f8f00fad619421bab2b503c8d2e99a7a50c62ea181f51efe2214d5f66c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
